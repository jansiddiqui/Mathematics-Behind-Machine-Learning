# -*- coding: utf-8 -*-
"""Vector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B7Hbj6qPG_hk0vI8ofOYFPQn0TsSPEtW
"""

import numpy as np
v=np.array([1,-1,2])
w=np.array([2,5,2])

print(v+w)

print(v-w)

#scaler Multi
print(3*v)

#nilalg = linear algebra
#norm = length
print(np.linalg.norm(v))

s=np.dot(v,w)
print(s)

# prompt: teach all about vector needed for machine learning in best way

import numpy as np

# Vectors in Machine Learning

# Vectors are fundamental to machine learning. They represent ordered lists of numbers,
# and can represent various data points, features, or parameters.  Understanding vector
# operations is crucial for many algorithms.

# 1. Vector Creation and Representation:
# In Python, NumPy arrays are the standard way to represent vectors.
v = np.array([1, -1, 2])
w = np.array([2, 5, 2])


# 2. Vector Addition and Subtraction:
# Element-wise addition and subtraction are basic vector operations.
print("v + w =", v + w)  # Output: [ 3  4  4]
print("v - w =", v - w)  # Output: [-1 -6  0]


# 3. Scalar Multiplication:
# Multiplying a vector by a scalar (a single number) multiplies each element by that scalar.
print("3 * v =", 3 * v)  # Output: [ 3 -3  6]


# 4. Vector Norm (Magnitude or Length):
# The norm of a vector represents its length or magnitude.  The most common norm is the Euclidean norm (L2 norm),
# which is calculated using the Pythagorean theorem.  NumPy provides a function for this.

print("||v|| (Euclidean norm) =", np.linalg.norm(v)) # Output: ~2.449


# 5. Dot Product:
# The dot product (also called scalar product or inner product) of two vectors is a scalar value.
# It's calculated as the sum of the products of corresponding elements. Geometrically, the dot product is
# related to the angle between the vectors.  A dot product of 0 means the vectors are orthogonal (perpendicular).


s = np.dot(v, w)
print("v • w (dot product) =", s)  # Output: 3


def normalize_vector(v):
    """
    Normalizes the given vector to have a magnitude of 1.
    
    Parameters:
    v (numpy.ndarray): Input vector to be normalized
    
    Returns:
    numpy.ndarray: Normalized vector (unit vector)
    """
    norm = np.linalg.norm(v)  # Calculate the magnitude (norm) of the vector
    if norm == 0:  # Prevent division by zero
        return v  # Return the original vector if it has zero length
    return v / norm  # Return the normalized vector


# Example applications:

# a. Representing data points: Each data point in a dataset can be represented as a vector. For example,
# in a 2D dataset, each point is a 2D vector (x, y).


# b. Representing features: Features of an object are often represented as a vector. For instance,
# an image could be represented by a vector where each element corresponds to a pixel value.

# c. Machine learning algorithms:  Many machine learning algorithms rely heavily on vector operations.
# Examples include:

# i. Linear Regression:  Uses dot products to predict target values.
# ii. Support Vector Machines (SVMs):   Uses vectors and their relationships (e.g., margins).
# iii. Principal Component Analysis (PCA):  Relies heavily on vector transformations to reduce dimensionality.

# Important Considerations:

# a. Vector Dimensionality:  Vectors can be of any dimension (1D, 2D, 3D, or higher). The dimensionality of
# a vector is the number of elements it contains.

# b. Vector Spaces:  Vectors exist in vector spaces, and vector operations are defined within those spaces.


# c. Linear Combinations:  Any linear combination of vectors is another vector (a*v + b*w, where a and b are scalars).

# With this improved explanation and examples, you'll be in a better position to grasp the significance of
# vectors in machine learning.

# prompt: now give the mcqs that can be asked from vector topics for the subject matematics behind machine learning

# Multiple Choice Questions on Vectors in Machine Learning

# 1. Which of the following best describes a vector in the context of machine learning?
# a) An unordered list of numbers
# b) A single numerical value
# c) An ordered list of numbers
# d) A matrix of numbers

# Correct answer: c


# 2. What is the result of the following vector operation in Python using NumPy?
#  v = np.array([1, 2, 3])
#  w = np.array([4, 5, 6])
#  result = v + w
# a) [5, 7, 9]
# b) [4, 10, 18]
# c) [0, -3, -3]
# d) An error

# Correct answer: a


# 3. Scalar multiplication of a vector involves:
# a) Adding a scalar to each element of the vector
# b) Multiplying each element of the vector by the scalar
# c) Dividing each element of the vector by the scalar
# d) Subtracting the scalar from each element of the vector

# Correct answer: b


# 4. The Euclidean norm of a vector represents its:
# a) Direction
# b) Magnitude
# c) Dimension
# d) Dot product with itself

# Correct answer: b


# 5. What does a dot product of zero between two vectors indicate?
# a) The vectors are parallel
# b) The vectors are orthogonal (perpendicular)
# c) The vectors have the same magnitude
# d) One of the vectors is the zero vector

# Correct answer: b


# 6.  In machine learning, vectors can be used to represent:
# a) Data points
# b) Features
# c) Parameters of a model
# d) All of the above

# Correct answer: d


# 7. Which machine learning algorithm heavily utilizes vector operations?
# a) Decision Trees
# b) Linear Regression
# c) K-Nearest Neighbors
# d) All of the above

# Correct answer: b (although others use them as well, Linear Regression is most directly dependent)


# 8. What is the dimensionality of the vector [1, -2, 3, 0]?
# a) 0
# b) 1
# c) 3
# d) 4

# Correct answer: d


# 9.  A linear combination of vectors results in:
# a) A scalar value
# b) Another vector
# c) A matrix
# d) None of the above

# Correct answer: b


# 10. What is the dot product of the vectors v = [1, 2] and w = [3, 4]?
# a) 7
# b) 11
# c) 8
# d) 5


#Correct Answer: b (1*3 + 2*4 = 11)

# prompt: now give the tough mcqs that can be asked from vector topics for the subject matematics behind machine learning

import numpy as np

# More challenging MCQs on Vectors

# 1.  Given vectors u = [2, 1, -3] and v = [-1, 0, 2], what is the cosine of the angle between them?
#     (Requires knowledge of dot product and magnitudes)

u = np.array([2, 1, -3])
v = np.array([-1, 0, 2])
dot_product = np.dot(u, v)
magnitude_u = np.linalg.norm(u)
magnitude_v = np.linalg.norm(v)
cosine_theta = dot_product / (magnitude_u * magnitude_v)
print(f"Cosine of the angle: {cosine_theta}") # Answer: -8/sqrt(14*5)

# 2.  If two vectors are orthogonal, what is their dot product?
#     (Fundamental concept)

# Answer: 0

# 3.  The projection of vector a onto vector b can be calculated as:
#     (Understanding projection)

# Answer: (a • b) * b / ||b||^2

# 4. Which of these operations is NOT commutative for vectors?
#     (Understanding commutative vs. non-commutative)

# a) Vector addition
# b) Vector subtraction
# c) Scalar multiplication
# d) Dot product


# Answer: b) Vector subtraction

# 5.  What is the cross product of vectors a = [1, 0, 0] and b = [0, 1, 0]?
#      (Requires knowledge of the cross product)


a = np.array([1, 0, 0])
b = np.array([0, 1, 0])
cross_product = np.cross(a,b)
print(f"Cross product: {cross_product}") # Answer: [0, 0, 1]



# 6.  A vector space must satisfy several axioms. Which of the following is NOT an axiom of a vector space?
#      (Theoretical understanding of vector spaces)

# a) Associativity of vector addition
# b) Existence of a zero vector
# c) Closure under scalar division
# d) Existence of additive inverses


# Answer:  c) Closure under scalar division (it's scalar multiplication)



#7.  Consider a set of vectors that are linearly independent. What can you say about the zero vector in this set?

# a) The zero vector must be included in the set.
# b) The zero vector is always included in any linearly independent set.
# c) The zero vector cannot be part of the set.
# d) The zero vector might or might not be part of the set.

# Answer: c) The zero vector cannot be part of the set

# 8. Two vectors are linearly dependent if:
# a) Their magnitudes are equal
# b) Their dot product is zero
# c) One is a scalar multiple of the other
# d) They point in opposite directions

# Answer: c) One is a scalar multiple of the other


#9. The span of a set of vectors is:
# a) The shortest distance between them
# b) All possible linear combinations of those vectors
# c) The set of all vectors perpendicular to the given vectors
# d) The magnitude of the resultant vector of all vectors in the set

#Answer: b) All possible linear combinations of those vectors

#10.  A basis for a vector space:
# a) Is a set of vectors that can represent any vector in the space through linear combination and are linearly dependent
# b) Is a set of vectors that can represent any vector in the space through linear combination and are linearly independent
# c) Is a vector that can represent any vector in the space
# d) Is a line in the vector space

# Answer: b) Is a set of vectors that can represent any vector in the space through linear combination and are linearly independent

